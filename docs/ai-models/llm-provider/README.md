# LLM Provider (AI Gateway) — Overview

Этот модуль инкапсулирует интеграции с внешними и локальными моделями (KServe), предоставляя единый контракт для оценивания работ и служебных инференсов.

## Цели

- Единый API для разных провайдеров (OpenAI, Anthropic, Local/KServe)
- Стандартизованные ответы по JSON Schema
- Политики таймаутов, ретраев, квот и стоимости
- Аудит запросов/ответов и трассировка

## Состав

- contracts.md — порт и форматы запрос/ответ
- providers.md — поддерживаемые провайдеры и конфигурация
- prompts.md — правила формирования промптов и схемы вывода
- retry-and-errors.md — ретраи, таймауты и таксономия ошибок
- test-plan.md — план тестирования качества/нагрузки
- openapi.yaml — спецификация REST интерфейса AI Gateway

## Потоки использования

1. Grading Core формирует контекст и вызывает /grade
1. Альтернативно — прямой вызов /models/{key}:infer для вспомогательных задач
1. Результат нормализуется и валидируется, сохраняется в Audit Store

## Связанные документы

- ../../architecture/hexagonal.md (ModelServingPort)
- ../ml-tasks-kserve.md (KServe интеграции)
- ../../api/openapi.yaml (общая спецификация продукта)
